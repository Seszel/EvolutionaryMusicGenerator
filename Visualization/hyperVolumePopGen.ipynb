{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pygmo as pg\n",
    "from pygmo import hypervolume\n",
    "\n",
    "fol = \"ExpNSGA_PopGen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_folder_path = '../EvolutionaryFramework/results/NSGA_II/' + fol\n",
    "\n",
    "target_folders = [folder for folder in os.listdir(parent_folder_path) if folder.startswith('2023_08')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023_08_18_16:42:31\n",
      "50 250\n",
      "2023_08_18_22:27:51\n",
      "500 250\n",
      "2023_08_18_16:59:12\n",
      "250 150\n",
      "2023_08_18_22:45:47\n",
      "500 1000\n",
      "Error parsing result_7.json: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result_0.json: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result_1.json: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result_2.json: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result_3.json: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result_4.json: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result_16.json: Expecting value: line 1 column 1 (char 0)\n",
      "Error parsing result_9.json: Expecting value: line 1 column 1 (char 0)\n",
      "2023_08_18_22:24:23\n",
      "500 150\n",
      "2023_08_18_16:52:06\n",
      "150 250\n",
      "2023_08_18_16:51:21\n",
      "150 100\n",
      "2023_08_18_22:21:47\n",
      "500 100\n",
      "2023_08_18_16:47:38\n",
      "100 250\n",
      "2023_08_19_00:10:24\n",
      "1000 500\n",
      "2023_08_18_16:40:29\n",
      "25 75\n",
      "2023_08_18_16:44:10\n",
      "75 75\n",
      "2023_08_18_16:40:18\n",
      "25 50\n",
      "2023_08_18_16:47:12\n",
      "100 100\n",
      "2023_08_18_16:44:51\n",
      "75 500\n",
      "2023_08_18_16:50:59\n",
      "150 50\n",
      "2023_08_18_16:47:22\n",
      "100 150\n",
      "2023_08_18_16:43:12\n",
      "50 1000\n",
      "2023_08_18_16:44:33\n",
      "75 250\n",
      "2023_08_18_23:35:25\n",
      "1000 150\n",
      "2023_08_18_16:42:24\n",
      "50 150\n",
      "2023_08_18_16:45:33\n",
      "75 1000\n",
      "2023_08_18_17:01:44\n",
      "250 500\n",
      "2023_08_18_16:52:49\n",
      "150 500\n",
      "2023_08_18_16:42:13\n",
      "50 50\n",
      "2023_08_18_16:46:58\n",
      "100 50\n",
      "2023_08_18_17:05:06\n",
      "250 1000\n",
      "2023_08_18_16:41:12\n",
      "25 500\n",
      "2023_08_18_16:41:40\n",
      "25 1000\n",
      "2023_08_18_23:26:48\n",
      "1000 100\n",
      "2023_08_18_22:18:40\n",
      "500 50\n",
      "2023_08_18_16:54:23\n",
      "150 1000\n",
      "2023_08_18_16:40:47\n",
      "25 150\n",
      "2023_08_18_16:44:15\n",
      "75 100\n",
      "2023_08_18_16:47:04\n",
      "100 75\n",
      "2023_08_18_17:00:08\n",
      "250 250\n",
      "2023_08_18_16:44:22\n",
      "75 150\n",
      "2023_08_18_16:40:39\n",
      "25 100\n",
      "2023_08_18_16:57:45\n",
      "250 50\n",
      "2023_08_18_23:20:17\n",
      "1000 75\n",
      "2023_08_18_16:40:55\n",
      "25 250\n",
      "2023_08_18_16:44:06\n",
      "75 50\n",
      "2023_08_18_16:58:05\n",
      "250 75\n",
      "2023_08_19_13:50:48\n",
      "1000 1000\n",
      "2023_08_18_16:58:33\n",
      "250 100\n",
      "2023_08_18_16:48:58\n",
      "100 1000\n",
      "2023_08_18_16:48:05\n",
      "100 500\n",
      "2023_08_18_16:42:16\n",
      "50 75\n",
      "2023_08_18_23:48:24\n",
      "1000 250\n",
      "2023_08_18_22:20:04\n",
      "500 75\n",
      "2023_08_18_16:42:19\n",
      "50 100\n",
      "2023_08_18_16:51:08\n",
      "150 75\n",
      "2023_08_18_23:15:43\n",
      "1000 50\n",
      "2023_08_18_16:42:43\n",
      "50 500\n",
      "2023_08_18_16:51:39\n",
      "150 150\n",
      "2023_08_18_22:33:49\n",
      "500 500\n",
      "Folder averages saved successfully.\n"
     ]
    }
   ],
   "source": [
    "folder_averages = {}\n",
    "\n",
    "metaCriteriaBool = False\n",
    "\n",
    "\n",
    "for folder in target_folders:\n",
    "    folder_path = os.path.join(parent_folder_path, folder)\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    metaBool = False\n",
    "    mutation = 0\n",
    "    crossover = 0\n",
    "    keyType = \"\"\n",
    "    criteria = []\n",
    "    result = 0\n",
    "    count = 0 \n",
    "\n",
    "\n",
    "    print(folder)\n",
    "\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            with open(file_path, encoding='utf-8') as f:\n",
    "                try:\n",
    "                    parsed_json = json.load(f)\n",
    "                    if metaBool == False:\n",
    "                        populationSize = parsed_json[\"metaParameters\"][\"populationSize\"]\n",
    "                        numberOfGeneration = parsed_json[\"metaParameters\"][\"numberOfGenerations\"]\n",
    "                        print(populationSize, numberOfGeneration)\n",
    "                        metaBool = True\n",
    "                    # print(parsed_json)  # Add this line to see parsed content\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error parsing {file}: {e}\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        if metaCriteriaBool == False:\n",
    "            for criterion in parsed_json[\"metaParameters\"]['criteria']:\n",
    "                criteria.append(criterion)\n",
    "            keyType = parsed_json[\"metaParameters\"][\"melodyKeyType\"]\n",
    "            \n",
    "\n",
    "        data = []\n",
    "        count += 1\n",
    "\n",
    "        for elem in parsed_json:\n",
    "            if elem == \"experiment\":\n",
    "                for individual in parsed_json[elem][f\"generation_{numberOfGeneration}\"][\"front_1\"]:\n",
    "                    dictionary = {}\n",
    "                    for criterion in criteria:\n",
    "                        fitness_value = individual['fitness'][criterion]\n",
    "                        if fitness_value is not None:\n",
    "                            dictionary[criterion] = -fitness_value\n",
    "                        else:\n",
    "                            dictionary[criterion] = None\n",
    "                    data.append(dictionary)    \n",
    "        data_df = pd.DataFrame(data)\n",
    "        data_df = data_df.dropna()\n",
    "    \n",
    "        hyper = pg.hypervolume(data_df.to_numpy())\n",
    "        result += hyper.compute([0.0, 0.0]) \n",
    "\n",
    "    folder_averages[keyType + \" \" + f\"generation_{numberOfGeneration} population_{populationSize} \" + \"cross_0.99\" + \"mut_0.5\" + \" \" + folder] = result/count\n",
    "        \n",
    "\n",
    "\n",
    "output_file = 'JSON/' + 'hyperVolume_PopGen.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(folder_averages, f, indent=4)\n",
    "\n",
    "print('Folder averages saved successfully.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
